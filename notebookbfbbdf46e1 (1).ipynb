{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":44224,"databundleVersionId":5188730,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport os\nfrom scipy.io import wavfile\n\nclass BirdClassDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = os.listdir(root_dir)\n        self.data = []\n        for i, bird_class in enumerate(self.classes):\n            class_path = os.path.join(root_dir, bird_class)\n            for file in os.listdir(class_path):\n                self.data.append((os.path.join(class_path, file), i))  # (file_path, class_index)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        file_path, class_idx = self.data[idx]\n        sample_rate, data = wavfile.read(file_path)\n        sample = {'audio': data, 'class_idx': class_idx}\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-07T10:08:41.634906Z","iopub.execute_input":"2024-06-07T10:08:41.635361Z","iopub.status.idle":"2024-06-07T10:08:41.648032Z","shell.execute_reply.started":"2024-06-07T10:08:41.635328Z","shell.execute_reply":"2024-06-07T10:08:41.646340Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BirdCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(BirdCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.pool(nn.functional.relu(self.conv1(x)))\n        x = self.pool(nn.functional.relu(self.conv2(x)))\n        x = self.pool(nn.functional.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 7 * 7)\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T10:08:43.225257Z","iopub.execute_input":"2024-06-07T10:08:43.225712Z","iopub.status.idle":"2024-06-07T10:08:43.240086Z","shell.execute_reply.started":"2024-06-07T10:08:43.225679Z","shell.execute_reply":"2024-06-07T10:08:43.238226Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\n# Définissez votre configuration\nANNOTATIONS_FILE = '/kaggle/input/birdclef-2023/train_metadata.csv'\nAUDIO_DIR = '/kaggle/input/birdclef-2023/train_audio'\nFOLDER_FILTERS = ['abethr1', 'abhori1', 'abythr1', 'afbfly1', 'afdfly1']\nSAMPLE_RATE = 16000\nNUM_SAMPLES = 16000\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 0.001\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Définir le dataset\nclass BirdClassDataset(Dataset):\n    def __init__(self, annotations_file, audio_dir, transformation, target_sample_rate, num_samples, device, folder_filters=None):\n        self.annotations = pd.read_csv(annotations_file)\n        self.audio_dir = audio_dir\n        self.device = device\n        self.transformation = transformation.to(self.device)\n        self.target_sample_rate = target_sample_rate\n        self.num_samples = num_samples\n        \n        if folder_filters is not None:\n            print(f\"Applying folder filters: {', '.join(folder_filters)}\")\n            initial_count = len(self.annotations)\n            self.annotations = self.annotations[self.annotations['filename'].str.contains('|'.join(folder_filters))]\n            filtered_count = len(self.annotations)\n            if filtered_count == 0:\n                raise ValueError(f\"No files found in folders: {', '.join(folder_filters)}\")\n            print(f\"Filtered dataset from {initial_count} to {filtered_count} samples.\")\n\n        self.annotations.reset_index(drop=True, inplace=True)\n        self.label_to_index = {label: idx for idx, label in enumerate(self.annotations['primary_label'].unique())}\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        audio_sample_path = self._get_audio_sample_path(index)\n        label = self._get_audio_sample_label(index)\n        signal, sr = torchaudio.load(audio_sample_path)\n        signal = signal.to(self.device)\n        signal = self._resample_if_necessary(signal, sr)\n        signal = self._mix_down_if_necessary(signal)\n        signal = self._cut_if_necessary(signal)\n        signal = self._right_pad_if_necessary(signal)\n        signal = self.transformation(signal)\n        return signal, label\n\n    def _cut_if_necessary(self, signal):\n        if signal.shape[1] > self.num_samples:\n            signal = signal[:, :self.num_samples]\n        return signal\n\n    def _right_pad_if_necessary(self, signal):\n        length_signal = signal.shape[1]\n        if length_signal < self.num_samples:\n            num_missing_samples = self.num_samples - length_signal\n            last_dim_padding = (0, num_missing_samples)\n            signal = torch.nn.functional.pad(signal, last_dim_padding)\n        return signal\n\n    def _resample_if_necessary(self, signal, sr):\n        if sr != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).to(self.device)\n            signal = resampler(signal)\n        return signal\n\n    def _mix_down_if_necessary(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n\n    def _get_audio_sample_path(self, index):\n        filename = self.annotations.iloc[index]['filename']\n        path = os.path.join(self.audio_dir, filename)\n        return path\n\n    def _get_audio_sample_label(self, index):\n        label = self.annotations.iloc[index]['primary_label']\n        label_index = self.label_to_index[label]\n        return label_index\n\nmel_spectrogram = torchaudio.transforms.MelSpectrogram(\n    sample_rate=SAMPLE_RATE,\n    n_mels=64,\n    n_fft=1024,\n    hop_length=512\n)\n\n# Charger toutes les annotations et filtrer si nécessaire\ndataset = BirdClassDataset(ANNOTATIONS_FILE, AUDIO_DIR, mel_spectrogram, SAMPLE_RATE, NUM_SAMPLES, device, folder_filters=FOLDER_FILTERS)\n\n# Diviser le dataset en ensemble d'entraînement et de validation\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nclass BirdCNN(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 16 * 8, 128)  # Corrected dimensions here\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.maxpool(x)\n        x = self.relu(self.conv2(x))\n        x = self.maxpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n# Instancier le modèle\nnum_classes = len(dataset.label_to_index)\nmodel = BirdCNN(num_classes=num_classes).to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# Fonction de formation\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 10 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n# Fonction de test\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n    return correct\n\n# Entraîner le modèle\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n    train(train_loader, model, loss_fn, optimizer)\n    accuracy = test(val_loader, model, loss_fn)\n    print(f\"Validation Accuracy: {accuracy:.2f}\")\n\n# Sauvegarder le modèle entraîné\ntorch.save(model.state_dict(), 'birdclef_cnn_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T10:12:38.772244Z","iopub.execute_input":"2024-06-07T10:12:38.772836Z","iopub.status.idle":"2024-06-07T10:17:34.894590Z","shell.execute_reply.started":"2024-06-07T10:12:38.772686Z","shell.execute_reply":"2024-06-07T10:17:34.893152Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Applying folder filters: abethr1, abhori1, abythr1, afbfly1, afdfly1\nFiltered dataset from 16941 to 218 samples.\nEpoch 1\n-------------------------------\nloss: 4.805730  [    0/  174]\nTest Error: \n Accuracy: 52.3%, Avg loss: 6.981363 \n\nValidation Accuracy: 0.52\nEpoch 2\n-------------------------------\nloss: 0.947601  [    0/  174]\nTest Error: \n Accuracy: 52.3%, Avg loss: 5.841698 \n\nValidation Accuracy: 0.52\nEpoch 3\n-------------------------------\nloss: 0.980016  [    0/  174]\nTest Error: \n Accuracy: 54.5%, Avg loss: 7.683813 \n\nValidation Accuracy: 0.55\nEpoch 4\n-------------------------------\nloss: 0.774240  [    0/  174]\nTest Error: \n Accuracy: 52.3%, Avg loss: 9.282438 \n\nValidation Accuracy: 0.52\nEpoch 5\n-------------------------------\nloss: 0.571560  [    0/  174]\nTest Error: \n Accuracy: 54.5%, Avg loss: 9.220858 \n\nValidation Accuracy: 0.55\nEpoch 6\n-------------------------------\nloss: 0.811113  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 9.448606 \n\nValidation Accuracy: 0.50\nEpoch 7\n-------------------------------\nloss: 0.314829  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 10.581024 \n\nValidation Accuracy: 0.50\nEpoch 8\n-------------------------------\nloss: 0.636124  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 11.234899 \n\nValidation Accuracy: 0.50\nEpoch 9\n-------------------------------\nloss: 0.554592  [    0/  174]\nTest Error: \n Accuracy: 47.7%, Avg loss: 12.161325 \n\nValidation Accuracy: 0.48\nEpoch 10\n-------------------------------\nloss: 0.458488  [    0/  174]\nTest Error: \n Accuracy: 47.7%, Avg loss: 13.365495 \n\nValidation Accuracy: 0.48\nEpoch 11\n-------------------------------\nloss: 0.389791  [    0/  174]\nTest Error: \n Accuracy: 45.5%, Avg loss: 14.125418 \n\nValidation Accuracy: 0.45\nEpoch 12\n-------------------------------\nloss: 0.398047  [    0/  174]\nTest Error: \n Accuracy: 47.7%, Avg loss: 14.343027 \n\nValidation Accuracy: 0.48\nEpoch 13\n-------------------------------\nloss: 0.605197  [    0/  174]\nTest Error: \n Accuracy: 47.7%, Avg loss: 16.199939 \n\nValidation Accuracy: 0.48\nEpoch 14\n-------------------------------\nloss: 0.556410  [    0/  174]\nTest Error: \n Accuracy: 45.5%, Avg loss: 19.106147 \n\nValidation Accuracy: 0.45\nEpoch 15\n-------------------------------\nloss: 0.557299  [    0/  174]\nTest Error: \n Accuracy: 47.7%, Avg loss: 5.551103 \n\nValidation Accuracy: 0.48\nEpoch 16\n-------------------------------\nloss: 0.515983  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 5.289031 \n\nValidation Accuracy: 0.50\nEpoch 17\n-------------------------------\nloss: 0.467763  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 5.873391 \n\nValidation Accuracy: 0.50\nEpoch 18\n-------------------------------\nloss: 0.349773  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 6.252137 \n\nValidation Accuracy: 0.50\nEpoch 19\n-------------------------------\nloss: 0.569961  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 6.636372 \n\nValidation Accuracy: 0.50\nEpoch 20\n-------------------------------\nloss: 0.312130  [    0/  174]\nTest Error: \n Accuracy: 50.0%, Avg loss: 7.549949 \n\nValidation Accuracy: 0.50\n","output_type":"stream"}]},{"cell_type":"code","source":"# Charger les poids du modèle entraîné\nmodel = BirdCNN(num_classes=num_classes).to(device)\nmodel.load_state_dict(torch.load('birdclef_cnn_model.pth'))\n\n# Définir une fonction pour prédire les étiquettes sur de nouvelles données\ndef predict_new_data(model, data_loader):\n    predictions = []\n    model.eval()\n    with torch.no_grad():\n        for X, _ in data_loader:\n            X = X.to(device)\n            outputs = model(X)\n            _, predicted = torch.max(outputs, 1)\n            predictions.extend(predicted.tolist())\n    return predictions\n\n# Charger de nouvelles données pour la prédiction\n# Assurez-vous de les prétraiter de la même manière que les données d'entraînement et de validation\n# Créez un DataLoader pour les nouvelles données, comme vous l'avez fait pour les données d'entraînement et de validation\n\n# Prédire les étiquettes sur les nouvelles données\nnew_data_predictions = predict_new_data(model, new_data_loader)\n\n# Afficher les prédictions\nprint(new_data_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T10:40:18.110670Z","iopub.execute_input":"2024-06-07T10:40:18.111185Z","iopub.status.idle":"2024-06-07T10:40:18.177829Z","shell.execute_reply.started":"2024-06-07T10:40:18.111150Z","shell.execute_reply":"2024-06-07T10:40:18.176308Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Charger de nouvelles données pour la prédiction\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Assurez-vous de les prétraiter de la même manière que les données d'entraînement et de validation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Créez un DataLoader pour les nouvelles données, comme vous l'avez fait pour les données d'entraînement et de validation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Prédire les étiquettes sur les nouvelles données\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m new_data_predictions \u001b[38;5;241m=\u001b[39m predict_new_data(model, \u001b[43mnew_data_loader\u001b[49m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Afficher les prédictions\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_data_predictions)\n","\u001b[0;31mNameError\u001b[0m: name 'new_data_loader' is not defined"],"ename":"NameError","evalue":"name 'new_data_loader' is not defined","output_type":"error"}]}]}